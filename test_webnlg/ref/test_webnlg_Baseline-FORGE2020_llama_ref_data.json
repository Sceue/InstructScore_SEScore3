{"type": "text2score", "instances": [{"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Abraham A. Ribicoff\u2019s birthplace is the USA where he worked for the United States Secretary of Health, Education, and Welfare office, in a country where African Americans are a national ethnic group. His spouse is Ruth Ribicoff.\". The model generated translation is \"Ruth Ribicoff is the spouse of Abraham A. Ribicoff, born in the United States. Abraham A. Ribicoff is in the United States Secretary of Health, Education, and Welfare. African Americans are an ethnic group of the United States.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 64.33333333333333, "DataCoverage": 71.33333333333333, "Fluency": 49.666666666666664, "Relevance": 68.33333333333333, "TextStructure": 50.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Aaron Turner is a post-metal musician from Massachusetts who plays the electric guitar. He started performing in 1995 and is a musician in the Lotus Eaters band.\". The model generated translation is \"Aaron Turner plays Post-metal and electric guitar and played with Lotus Eaters. Aaron Turner, active from 1995, is from Massachusetts.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.66666666666667, "DataCoverage": 100.0, "Fluency": 75.0, "Relevance": 100.0, "TextStructure": 88.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Peso is currency used by Mexicans in Mexico. Bionico is a dessert that can be found in Guadalajara, Mexico. Cookies are also a type of dessert.\". The model generated translation is \"Bionico, found in Guadalajara, is a dessert. It comes from Mexico. Cookie can be a variation of Dessert. The currency of Mexico is the Mexican peso. Mexicans live in Mexico.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 80.0, "DataCoverage": 99.66666666666667, "Fluency": 48.333333333333336, "Relevance": 98.33333333333333, "TextStructure": 90.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The city of Bangalore, founded in the state of Karnataka, India By Kempe Gowda I, is home to the Acharya Institute of Technology. Its campus with Technical Status designated by the All India Technical Council for Technical Education in Mumbai, is located at Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore \u2013 560090, and the institute is directed by Dr. G.P. Prabhukumar.\". The model generated translation is \"Acharya Institute of Technology, the director of which is Dr. G. P. Prabhukumar, is located at In Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore \u2013 560090. The Acharya Institute of Technology, to which All India Council for Technical Education gave the status of 'Technical Campus', is in Bangalore, Karnataka. All India Council for Technical Education is in Mumbai. Kempe Gowda I is the founder of Bangalore.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 85.33333333333333, "DataCoverage": 91.0, "Fluency": 72.33333333333333, "Relevance": 86.0, "TextStructure": 75.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The apoapsis of 1147 Stavropolis is 418476000000.0. Its orbital period of is 1249.6 days, and it was discovered by Grigory Neujmin.\". The model generated translation is \"The apoapsis of 1147 Stavropolis, the orbital period of which is 1,249.6, is 418,476,000,000. Grigory Neujmin discovered 1147 Stavropolis.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 87.0, "DataCoverage": 98.33333333333333, "Fluency": 35.333333333333336, "Relevance": 98.0, "TextStructure": 45.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Piotr Hallmann was born on August 25, 1987 and he weighs 70.308 kilograms.\". The model generated translation is \"The weight of Piotr Hallmann, born on August 25, 1987, is 70.308.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 92.0, "Relevance": 100.0, "TextStructure": 90.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Lady Anne Monson was born in Darlington, in the Kingdom of England, on January 1st, 1726. Her nationality was with the Kingdom of England, but her residence was in India. She passed away on February 18th, 1776.\". The model generated translation is \"Lady Anne Monson, who died on February 18, 1776, was born on January 01, 1726 in Darlington, the Kingdom of England. She is from the Kingdom of England. She lives in India.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 82.33333333333333, "DataCoverage": 86.33333333333333, "Fluency": 58.666666666666664, "Relevance": 90.0, "TextStructure": 72.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"English Without Tears producer Anatole de Grunwald was born in Saint Petersburg.\". The model generated translation is \"Anatole de Grunwald, born in Saint Petersburg, produced English Without Tears.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 91.5, "Relevance": 100.0, "TextStructure": 92.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Brandon Carter was born on January 1, 1942 and worked professionally in the field of General Relativity. Brandon Carter was known for the Carter Constant and his contributions to the no-hair theorem. Dennis William Sciama was his doctoral advisor.\". The model generated translation is \"Brandon Carter, known for the Carter constant and the No-hair theorem, worked in General relativity. He was the doctoral adviser of Dennis William Sciama. He was born on January 01, 1942.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 89.33333333333333, "DataCoverage": 96.0, "Fluency": 87.66666666666667, "Relevance": 96.0, "TextStructure": 91.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Al Asad Airbase has a runway length of 3,992.88 and is run by the United States Air Force.\". The model generated translation is \"United States Air Force operates Al Asad Airbase. The length of its runway is 3,992.88.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.66666666666667, "DataCoverage": 100.0, "Fluency": 98.33333333333333, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Train song Mermaid is followed by the John Lennon song Imagine.\". The model generated translation is \"Imagine follows Mermaid.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 79.33333333333333, "DataCoverage": 76.0, "Fluency": 74.33333333333333, "Relevance": 80.33333333333333, "TextStructure": 64.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Darinka Dentcheva is a citizen of the United States who works in the field of Mathematical optimization.\". The model generated translation is \"Darinka Dentcheva, who worked in Mathematical optimization, is from the United States.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 80.66666666666667, "DataCoverage": 74.66666666666667, "Fluency": 73.66666666666667, "Relevance": 72.0, "TextStructure": 88.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nurhan Atasoy was born on January 1st 1934 in Turkey.\". The model generated translation is \"Nurhan Atasoy was born in Turkey on January 01, 1934.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.66666666666667, "DataCoverage": 97.0, "Fluency": 96.33333333333333, "Relevance": 90.66666666666667, "TextStructure": 99.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Ciudad Ayala is a city with population density of 1604.0 and the population of the metropolitan area is 1,777,539. One of the leaders of Ciudad Ayala is the City Manager.\". The model generated translation is \"The metropolitan area of Ciudad Ayala has a population of 1,777,539. The City Manager governs Ciudad Ayala, which is a city. The population density of Ciudad Ayala is 1,604.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 79.0, "DataCoverage": 89.66666666666667, "Fluency": 95.33333333333333, "Relevance": 96.0, "TextStructure": 91.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The number of employees at Hypermarcas is 10252.\". The model generated translation is \"Hypermarcas has 10,252 employees.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.66666666666667, "DataCoverage": 100.0, "Fluency": 98.66666666666667, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The album Expect a miracle is of the easy instrumental Listening music genre.\". The model generated translation is \"Expect a Miracle is Instrumental music and Easy listening.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 87.0, "DataCoverage": 84.33333333333333, "Fluency": 49.333333333333336, "Relevance": 88.33333333333333, "TextStructure": 69.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Bootleg Series Volume 1: The Quine Tapes was released by Universal Music Group, a record label run by key person Lucian Grainge. Polydor Records recorded Bootleg Series Volume 1: The Quine Tapes.\". The model generated translation is \"The labels of Bootleg Series Volume 1: The Quine Tapes are Polydor Records and Universal Music Group. Lucian Grainge is a key person at Universal Music Group.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 77.5, "DataCoverage": 100.0, "Fluency": 76.0, "Relevance": 100.0, "TextStructure": 81.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Justin Whalin stars in Super Capers, which is written by director Ray Griggs.\". The model generated translation is \"Justin Whalin stars in Super Capers, which Ray Griggs wrote.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.33333333333333, "DataCoverage": 98.33333333333333, "Fluency": 76.66666666666667, "Relevance": 100.0, "TextStructure": 93.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"MotorSport Vision, founded in 2004 by Jonathan Palmer, operates the Bedford Aerodrome in Thurleigh.\". The model generated translation is \"MotorSport Vision operates Bedford Aerodrome, which is in Thurleigh. Jonathan Palmer founded it and it was founded in 2004.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 90.0, "DataCoverage": 97.33333333333333, "Fluency": 81.0, "Relevance": 93.33333333333333, "TextStructure": 80.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The BBC tv series, Bananaman, created by Steve Bright and starred Bill Oddie, who was born in Rochdale. The BBC Headquarters is referred to as Broadcasting House.\". The model generated translation is \"Bill Oddie, born in Rochdale, stars in Bananaman, which Steve Bright created. BBC, which is in Broadcasting House, broadcasts it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 87.0, "DataCoverage": 93.0, "Fluency": 83.0, "Relevance": 91.33333333333333, "TextStructure": 88.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nurhan Atasoy's date of birth is January 1, 1934.\". The model generated translation is \"Nurhan Atasoy was born on January 01, 1934.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 98.66666666666667, "Fluency": 99.0, "Relevance": 99.0, "TextStructure": 99.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"While pop rock can trace its stylistic roots back to rock music, Reggae music evolved out of different musical genre, known as ska. Interestingly, the Train song, Mermaid, belongs to the genre of pop rock, but is also considered to be of the reggae genre as well.\". The model generated translation is \"Mermaid is Pop rock and Reggae. Pop rock originates from Rock music. Reggae originates from Ska.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 83.66666666666667, "DataCoverage": 89.0, "Fluency": 70.33333333333333, "Relevance": 90.33333333333333, "TextStructure": 74.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nurhan Atasoy, who was born on January 01, 1934 in Turkey, currently also resides there (Istanbul) and has both Turkish nationality and citizenship.\". The model generated translation is \"Nurhan Atasoy, who lives in Istanbul and Turkey, was born in Turkey on January 01, 1934. She is from Turkey and Turkish people.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.33333333333333, "DataCoverage": 96.66666666666667, "Fluency": 75.0, "Relevance": 100.0, "TextStructure": 81.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Louis Levy, who was born on November 20, 1894, is the music composer for the film \"It's Great to be Young.\"\". The model generated translation is \"Louis Levy, born on November 20, 1894, composed the music of It's Great to Be Young.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.0, "DataCoverage": 96.66666666666667, "Fluency": 95.33333333333333, "Relevance": 100.0, "TextStructure": 95.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Piotr Hallmann weighs 70.308 kilograms and was born in Gdynia, Poland, which follows the Central European Summer Time timezone.\". The model generated translation is \"Piotr Hallmann, whose weight is 70.308, was born in Gdynia, Poland. Gdynia, Poland is in the Central European Time time zone.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 85.66666666666667, "DataCoverage": 83.33333333333333, "Fluency": 80.66666666666667, "Relevance": 98.0, "TextStructure": 88.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Olga Bondareva, who was born on April 27, 1937, graduated from Leningrad State University.\". The model generated translation is \"Olga Bondareva, who graduated from Leningrad State University, was born on April 27, 1937.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 88.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The College of WIlliam and Mary is the current owner of Alan B. Miller Hall and the Mason School of Business is the current tenants.\". The model generated translation is \"Alan B. Miller Hall, which is owned by College of William & Mary, houses the Mason School of Business.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 99.0, "Relevance": 98.0, "TextStructure": 99.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"A monument to the 11th Mississippi Infantry was erected in 2000 categorised as a contributing property and stands in the state of Pennsylvania in the municipality of Gettysburg in Pennsylvania located in Adams County, Pennsylvania. Carroll County Maryland is southeast and Pennsylvania's Cumberland County is to the north of the Adams County.\". The model generated translation is \"11th Mississippi Infantry Monument, which is in Adams County, Pennsylvania (contributing property), Pennsylvania, Gettysburg, Pennsylvania, was established in 2000. Carroll County, Maryland is located to the southeast of Adams County, Pennsylvania. Cumberland County, Pennsylvania is located to the north of Adams County, Pennsylvania.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 93.33333333333333, "DataCoverage": 91.0, "Fluency": 89.0, "Relevance": 100.0, "TextStructure": 90.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"\"Agremia\u00e7\u00e3o Sportiva Arapiraquense\" is the full name of the Agremia\u00e7\u00e3o Sportiva Arapiraquense club, which has 17000 members. They play in the Campeonato Brasileiro S\u00e9rie C league on their ground Estadio Municipal Coaracy da Mata Fonseca located in Arapiraca. The championship is based in Brazil and Vila Nova Futebol Clube are the champions.\". The model generated translation is \"The champions of the Campeonato Brasileiro S\u00e9rie C, which is in Brazil, are Vila Nova Futebol Clube. Agremia\u00e7\u00e3o Sportiva Arapiraquense play in Campeonato Brasileiro S\u00e9rie C and are their full name. Their stadium has 17,000 seats. Agremia\u00e7\u00e3o Sportiva Arapiraquense play their home games in Est\u00e1dio Municipal Coaracy da Mata Fonseca. Est\u00e1dio Municipal Coaracy da Mata Fonseca is in Arapiraca.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 91.66666666666667, "Relevance": 100.0, "TextStructure": 91.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Piotr Hallmann's birthplace was in Gdynia, Poland on August 25th. 1987 and he is 175.26 cm tall.\". The model generated translation is \"Piotr Hallmann, born in Gdynia, Poland on August 25, 1987, measures 175.26 centimetres.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.33333333333333, "DataCoverage": 100.0, "Fluency": 91.66666666666667, "Relevance": 100.0, "TextStructure": 98.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nurhan Atasoy was born in Re\u015fadiye.\". The model generated translation is \"Nurhan Atasoy was born in Re\u015fadiye.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nord is an album by Year Of No Light that falls under the genres of sludge metal and post-metal. It was released in September 6th, 2006. The next album Year Of No Light released was Live at Roadburn 2008.\". The model generated translation is \"Nord, which Live at Roadburn 2008 follows, was released on September 06, 2006. It is Sludge metal and Post-metal.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 95.66666666666667, "DataCoverage": 100.0, "Fluency": 85.0, "Relevance": 95.66666666666667, "TextStructure": 90.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Alan Shepard, an American, who went to school at NWC and graduated with an MA in 1957 and who was the Chief of the Astronaut Office in 1963, was born in New Hampshire on Nov 18, 1923 and died in California.\". The model generated translation is \"Alan Shepard, who is from the United States, was born in New Hampshire on November 18, 1923. He served as Chief of the Astronaut Office in 1963 and died in California. He graduated from NWC in 1957 with a M.A.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.33333333333333, "DataCoverage": 100.0, "Fluency": 93.33333333333333, "Relevance": 100.0, "TextStructure": 94.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Year of No Light album Nord is in the sludge metal genre, one variety of which is southern sludge.\". The model generated translation is \"Nord is Sludge metal, the subgenre of which is Southern sludge.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.0, "DataCoverage": 100.0, "Fluency": 92.0, "Relevance": 87.0, "TextStructure": 88.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Andrzej Piotr Ruszczy\u0144ski is known for his work with stochastic programming.\". The model generated translation is \"Andrzej Piotr Ruszczy\u0144ski is known for the Stochastic programming.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 93.0, "DataCoverage": 95.66666666666667, "Fluency": 87.66666666666667, "Relevance": 95.66666666666667, "TextStructure": 90.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"1147 Stavropolis is an asteroid, discovered on 11 June 1929 by Grigory Neujmin. Its absolute magnitude is 11.5, and it has a rotation period of 20378.5. Its periapsis is 260855000000.0, orbital period is 1249.6 and the apoapsis is 418476000000.0 AU.\". The model generated translation is \"The apoapsis of 1147 Stavropolis, the orbital period of which is 1,249.6, is 418,476,000,000. Grigory Neujmin discovered 1147 Stavropolis and 1147 Stavropolis was discovered on June 11, 1929. The magnitude of 1147 Stavropolis is 11.5. The rotation period of 1147 Stavropolis is 20,378.5. The periapsis of 1147 Stavropolis is 260,855,000,000.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.0, "DataCoverage": 96.33333333333333, "Fluency": 78.33333333333333, "Relevance": 98.66666666666667, "TextStructure": 76.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Est\u00e1dio Municipal Coaracy da Mata Fonseca is a sports ground which is based in Arapiraca and used by the team Agremia\u00e7\u00e3o Sportiva Arapiraquense. Agremia\u00e7\u00e3o Sportiva Arapiraquense played in the 2015 season of the Brazil based Campeonato Brasileiro S\u00e9rie C league. Vila Nova Futebol Clube have been previous champions of the Campeonato Brasileiro S\u00e9rie C league.\". The model generated translation is \"Agremia\u00e7\u00e3o Sportiva Arapiraquense play in Campeonato Brasileiro S\u00e9rie C, the champions of which are Vila Nova Futebol Clube. They played in the 2015 season. They play their home games in Est\u00e1dio Municipal Coaracy da Mata Fonseca. Est\u00e1dio Municipal Coaracy da Mata Fonseca is in Arapiraca. Campeonato Brasileiro S\u00e9rie C is in Brazil.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 89.66666666666667, "DataCoverage": 97.33333333333333, "Fluency": 66.33333333333333, "Relevance": 95.66666666666667, "TextStructure": 83.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Velvet Underground Squeeze album was succeeded by the rock album Bootleg Series Volume 1: The Quine Tapes, recorded under record label Polydor Records in San Francisco.\". The model generated translation is \"Bootleg Series Volume 1: The Quine Tapes, which follows Squeeze, is Rock music. Its label is Polydor Records. Bootleg Series Volume 1: The Quine Tapes was recorded in San Francisco.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.66666666666667, "DataCoverage": 96.66666666666667, "Fluency": 92.33333333333333, "Relevance": 100.0, "TextStructure": 98.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Director Ray Griggs, born in 1974, is the writer of the film Super Capers, starring Michael Rooker and Tom Sizemore.\". The model generated translation is \"Ray Griggs, born in 1974, wrote Super Capers, in which Michael Rooker and Tom Sizemore star.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 95.0, "DataCoverage": 94.0, "Fluency": 94.0, "Relevance": 93.33333333333333, "TextStructure": 94.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Super Capers, a movie directed by Ray Griggs, was distributed by both Lionsgate and Roadside Attractions and had a 98 minute run time.\". The model generated translation is \"The distributors of Super Capers, the director of which is Ray Griggs, are Lionsgate and Roadside Attractions. Super Capers has a runtime of 98.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 95.66666666666667, "DataCoverage": 98.0, "Fluency": 86.33333333333333, "Relevance": 100.0, "TextStructure": 92.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nurhan Atasoy, a Turkish national residing in Istanbul was born on 1934-01-01 in Turkey.\". The model generated translation is \"Nurhan Atasoy, who lives in Istanbul, was born in Turkey on January 01, 1934. She is from Turkey.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.66666666666667, "DataCoverage": 81.66666666666667, "Fluency": 87.66666666666667, "Relevance": 96.0, "TextStructure": 91.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"In the United States, one of the national ethnic groups are the African Americans. The United States is where Abraham A. Ribicoff, who was married to Casey Ribicoff, died.\". The model generated translation is \"Casey Ribicoff is the spouse of Abraham A. Ribicoff, which died in the United States. African Americans are an ethnic group of the United States.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 65.5, "Relevance": 100.0, "TextStructure": 77.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The University of Burgundy in Dijon has 2,900 staff members along with 27,400 students, of which 9,400 are postgraduate students and 1,299 are PhD students.\". The model generated translation is \"University of Burgundy, which is located at Dijon, has 2,900 staff members, 1,299 doctoral students, 27,400 students and 9,400 postgraduate students.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.66666666666667, "DataCoverage": 97.33333333333333, "Fluency": 99.66666666666667, "Relevance": 99.0, "TextStructure": 98.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The architect of Alan B Miller Hall, owned by The College of William and Mary, is Robert A M Stern and it is situated at 101 Ukrop Way, Virginia, USA. They started to build the Alan B Miller Hall on the 30th of March, 2007 and The Mason School of Business are now its tenants.\". The model generated translation is \"Robert A. M. Stern designed Alan B. Miller Hall, which is located at 101 Ukrop Way. The construction of Alan B. Miller Hall began in 30 March 2007. Alan B. Miller Hall, which is in Virginia, houses the Mason School of Business, which is in the United States. College of William & Mary owns it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.0, "DataCoverage": 100.0, "Fluency": 71.66666666666667, "Relevance": 99.33333333333333, "TextStructure": 85.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Hypermarcas, a type of S.A. (corporation), was founded on January 1, 2001, and has a subsidiary called Mantecorp.\". The model generated translation is \"Hypermarcas, which is a s.a., was founded on January 01, 2001. It owns Mantecorp.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 89.5, "DataCoverage": 91.5, "Fluency": 83.5, "Relevance": 92.5, "TextStructure": 87.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The American band, the Honeymoon Killers, self-produced its album Turn Me On, with the help of some musicians from an associated musical group called Pussy Galore.\". The model generated translation is \"The Honeymoon Killers, which played with Pussy Galore, produced Turn Me On.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 92.33333333333333, "DataCoverage": 95.66666666666667, "Fluency": 84.0, "Relevance": 95.66666666666667, "TextStructure": 87.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Est\u00e1dio Municipal Coaracy da Mata Fonseca is located in Arapiraca. It is the ground of Agremia\u00e7\u00e3o Sportiva Arapiraquense who play in the Campeonato Brasileiro S\u00e9rie C league and have 17000 members. The full name of the club is \"Agremia\u00e7\u00e3o Sportiva Arapiraquense\"\". The model generated translation is \"Est\u00e1dio Municipal Coaracy da Mata Fonseca, in which Agremia\u00e7\u00e3o Sportiva Arapiraquense play their home games, is in Arapiraca. Agremia\u00e7\u00e3o Sportiva Arapiraquense play in Campeonato Brasileiro S\u00e9rie C. Their stadium has 17,000 seats. The full name of Agremia\u00e7\u00e3o Sportiva Arapiraquense is Agremia\u00e7\u00e3o Sportiva Arapiraquense.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 91.33333333333333, "DataCoverage": 94.0, "Fluency": 80.0, "Relevance": 89.33333333333333, "TextStructure": 92.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The University of Burgundy is located in Dijon in France, which is also known as the French Republic and led by Claude Bartolone.\". The model generated translation is \"University of Burgundy is in France, Dijon. The full name of France, the leader of which is Claude Bartolone, is French Republic.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 74.66666666666667, "DataCoverage": 78.0, "Fluency": 43.666666666666664, "Relevance": 84.33333333333333, "TextStructure": 70.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The rock album \"Bootleg Series Volume 1: The Quine Tapes\" was produced by proto-punk band The Velvet Underground.\". The model generated translation is \"The Velvet Underground, which are Proto-punk, produced Bootleg Series Volume 1: The Quine Tapes, which is Rock music.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 94.0, "Fluency": 82.0, "Relevance": 100.0, "TextStructure": 83.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"1634: The Bavarian Crisis which has 448 pages, was written by Eric Flint.\". The model generated translation is \"1634: The Bavarian Crisis, which Eric Flint wrote, has 448 pages.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.0, "DataCoverage": 98.66666666666667, "Fluency": 99.0, "Relevance": 96.66666666666667, "TextStructure": 97.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The album Turn Me On is punk blues, a genre which originated from the earlier garage rock sound.\". The model generated translation is \"Turn Me On is Punk blues, which originates from Garage rock.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.66666666666667, "DataCoverage": 100.0, "Fluency": 94.33333333333333, "Relevance": 99.66666666666667, "TextStructure": 93.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"ENAIRE, located in Madrid, is the operating organisation for Adolfo Suarez Madrid-Barajas airport in Alcobendas. The airport is elevated 610 metres above sea level and its runway name is 14L/32R.\". The model generated translation is \"ENAIRE, which serves Madrid, operates Adolfo Su\u00e1rez Madrid\u2013Barajas Airport, which is in Alcobendas and 610 metres above the sea level. The name of its runway is 14L/32R.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 94.66666666666667, "Relevance": 94.33333333333333, "TextStructure": 89.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Lionsgate provides digital distribution service.\". The model generated translation is \"Lionsgate offers Digital distribution services.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.33333333333333, "DataCoverage": 99.33333333333333, "Fluency": 97.33333333333333, "Relevance": 99.33333333333333, "TextStructure": 99.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"J.R.R. Tolkien wrote The Fellowship of the Ring which was released on July 29, 1954. The Hobbit was released first, followed by The Fellowship of the Ring, and then The Two Towers.\". The model generated translation is \"The Two Towers follows The Fellowship of the Ring, which J. R. R. Tolkien wrote. The Fellowship of the Ring, which follows The Hobbit, was released on July 29, 1954.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 92.33333333333333, "DataCoverage": 95.66666666666667, "Fluency": 55.666666666666664, "Relevance": 93.66666666666667, "TextStructure": 93.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Post-hardcore is a derivative of noise rock.\". The model generated translation is \"Noise rock has been an influence on Post-hardcore.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 69.66666666666667, "DataCoverage": 73.66666666666667, "Fluency": 79.66666666666667, "Relevance": 63.666666666666664, "TextStructure": 98.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The University of Burgundy has a 2900 member staff. The university, located in Dijon, serves 1299 doctoral students.\". The model generated translation is \"University of Burgundy, which is located at Dijon, has 2,900 staff members and 1,299 doctoral students. It is in Dijon.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 87.66666666666667, "DataCoverage": 89.0, "Fluency": 94.33333333333333, "Relevance": 92.66666666666667, "TextStructure": 95.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The film Super Capers, distributed by Lionsgate and starring Justin Whalin, grossed $30,955.\". The model generated translation is \"The distributor of Super Capers, in which Justin Whalin stars, is Lionsgate. Super Capers grossed $30,955 at the box office.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.66666666666667, "DataCoverage": 97.66666666666667, "Fluency": 78.33333333333333, "Relevance": 98.66666666666667, "TextStructure": 84.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Liselotte Grschebina was born 115 meters above sea-level, in Karlsruhe, in the German Empire, where the currency is the German Papiermark.\". The model generated translation is \"Liselotte Grschebina was born in the German Empire, Karlsruhe. The currency of the German Empire is the German Papiermark. Karlsruhe is 115 metres above the sea level.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 93.0, "DataCoverage": 95.0, "Fluency": 62.0, "Relevance": 90.33333333333333, "TextStructure": 79.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The band Train were signed to the record label Warner Music Group.\". The model generated translation is \"The label of Train is Warner Music Group.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.33333333333333, "DataCoverage": 95.0, "Fluency": 88.0, "Relevance": 99.33333333333333, "TextStructure": 81.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Dr. G. P. Prabhukumar is the director of the Acharya Institute of Technology. Its address is Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore - 560090. The All India Council for Technical Education, located in Mumbai, was proud to give the Technical Campus status to the Acharya Institute of Technology.\". The model generated translation is \"Acharya Institute of Technology, the director of which is Dr. G. P. Prabhukumar, is located at In Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore \u2013 560090. The Acharya Institute of Technology, to which All India Council for Technical Education gave the status of 'Technical Campus', is in Bangalore. All India Council for Technical Education is in Mumbai.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.66666666666667, "DataCoverage": 96.33333333333333, "Fluency": 75.0, "Relevance": 100.0, "TextStructure": 78.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Olga Bondareva, born in Leningrad of the USSR, is an economist and mathematician who died in Saint Petersburg on December 9, 1991.\". The model generated translation is \"Olga Bondareva, who died in Saint Petersburg on December 09, 1991, was born in Leningrad, USSR. She worked in Economics and Mathematics.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 92.33333333333333, "DataCoverage": 89.0, "Fluency": 84.0, "Relevance": 95.66666666666667, "TextStructure": 83.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The leader title for Ciudad Ayala is City Manager.\". The model generated translation is \"The City Manager governs Ciudad Ayala.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.0, "DataCoverage": 99.66666666666667, "Fluency": 99.0, "Relevance": 99.66666666666667, "TextStructure": 99.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Jamie Lawrence is the music composer of the 83 minute 'Death on a Factory Farm' film, directed by Sarah Teale.\". The model generated translation is \"Jamie Lawrence composed the music of Death on a Factory Farm. Death on a Factory Farm, the director of which is Sarah Teale, has a runtime of 83.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 88.66666666666667, "DataCoverage": 92.0, "Fluency": 54.666666666666664, "Relevance": 83.0, "TextStructure": 69.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The full name of the country Israel is the State of Israel.\". The model generated translation is \"The full name of Israel is State of Israel.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.5, "DataCoverage": 99.0, "Fluency": 97.5, "Relevance": 100.0, "TextStructure": 99.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The University of Burgundy, located in the city of Dijon (postal code 21000), has 16,800 undergraduate students and 2,900 staff members.\". The model generated translation is \"The University of Burgundy, which has 16,800 undergraduate students and 2,900 staff members, is in Dijon, the postal code of which is 21000.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 92.66666666666667, "DataCoverage": 95.33333333333333, "Fluency": 90.0, "Relevance": 95.66666666666667, "TextStructure": 93.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Hypermarcas, a company that makes healthcare products and sells cosmetics, employs 10,252 people. Hypermarcas had a net income of $108,600,000 and its revenue is $1,800,000,000.\". The model generated translation is \"Hypermarcas, which produces healthcare and cosmetics, has a net income of $108,600,000. Hypermarcas, which reported a revenue of $1,800,000,000, has 10,252 employees.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.33333333333333, "DataCoverage": 95.0, "Fluency": 91.33333333333333, "Relevance": 96.0, "TextStructure": 95.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Lady Anne Monson\u2019s nationality is English but currently resides in India, whose total area is 3,287,590 km^2. One of the leaders of India is Chief Justice.\". The model generated translation is \"Lady Anne Monson, who lives in India, is from the Kingdom of England. The total area of India, which the Chief Justice governs, is 3,287,590,000,000.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.33333333333333, "DataCoverage": 99.33333333333333, "Fluency": 91.33333333333333, "Relevance": 95.33333333333333, "TextStructure": 93.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"GMA New Media is a company in the mass media industry whose headquarters are located in the GMA Network Center.\". The model generated translation is \"GMA New Media is in GMA Network Center in the mass media sector.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.66666666666667, "DataCoverage": 66.66666666666667, "Fluency": 93.0, "Relevance": 66.66666666666667, "TextStructure": 96.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Death on a Factory Farm is a film broadcasted by HBO, formerly known as The Green Channel.\". The model generated translation is \"HBO, which was formerly known as The Green Channel, broadcasts Death on a Factory Farm.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 85.33333333333333, "DataCoverage": 90.33333333333333, "Fluency": 74.33333333333333, "Relevance": 92.33333333333333, "TextStructure": 80.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"GMA New Media, Inc. is a subsidiary of GMA Network.\". The model generated translation is \"The parent company of GMA New Media is GMA Network.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.0, "DataCoverage": 97.33333333333333, "Fluency": 96.66666666666667, "Relevance": 96.0, "TextStructure": 96.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Aleksandr Prudnikov plays for FC Terek Grozny (based at Grozny) and managed by Rashid Rakhimov.Aleksandr Prudnikov played for FC Spartak Moscow's youth team an his current club is FC Amkar Perm.\". The model generated translation is \"Aleksandr Prudnikov currently plays for FC Amkar Perm. He played for FC Terek Grozny and for the FC Spartak Moscow youthclub. FC Terek Grozny, the manager of which is Rashid Rakhimov, play their home games in Grozny.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 92.0, "DataCoverage": 93.33333333333333, "Fluency": 79.66666666666667, "Relevance": 91.0, "TextStructure": 82.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Aleksandr Prudnikov was born on 1989-02-24 and plays for FC Amkar Perm. He was also a member of the youth side of FC Spartak Moscow.\". The model generated translation is \"Aleksandr Prudnikov, born on February 24, 1989, played for FC Amkar Perm and the FC Spartak Moscow youthclub. He currently plays for FC Amkar Perm.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 99.0, "Relevance": 97.33333333333333, "TextStructure": 97.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Bootleg Series Volume I: The Quine Tapes's genre is rock, of which proto-punk is a musical subgenre.\". The model generated translation is \"Bootleg Series Volume 1: The Quine Tapes is Rock music, the subgenre of which is Proto-punk.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.66666666666667, "DataCoverage": 100.0, "Fluency": 87.66666666666667, "Relevance": 100.0, "TextStructure": 91.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The University of Burgundy is located in the city of Dijon in France.\". The model generated translation is \"The University of Burgundy is in Dijon, France.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Honeymoon Killers is the producer of the Turn Me On album.\". The model generated translation is \"The Honeymoon Killers produced Turn Me On.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 83.33333333333333, "Fluency": 96.66666666666667, "Relevance": 98.66666666666667, "TextStructure": 95.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"George Allen & Unwin published the Fellowship of the Ring.\". The model generated translation is \"George Allen & Unwin publishes The Fellowship of the Ring.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.33333333333333, "DataCoverage": 93.33333333333333, "Fluency": 95.0, "Relevance": 94.66666666666667, "TextStructure": 93.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Bionico dessert is a food found in Mexico (currency: peso). Sandesh is also a dessert.\". The model generated translation is \"Bionico, which comes from Mexico, is a dessert. Sandesh can be a variation of Dessert. The currency of Mexico is the Mexican peso.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 93.66666666666667, "DataCoverage": 99.0, "Fluency": 82.33333333333333, "Relevance": 99.33333333333333, "TextStructure": 97.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The album Nord by the artist Year of No Light, was released by the record label Crucial blast on the E-Vinyl record label.\". The model generated translation is \"Year of No Light wrote Nord, the labels of which are Crucial Blast and E-Vinyl.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 88.33333333333333, "DataCoverage": 85.66666666666667, "Fluency": 81.66666666666667, "Relevance": 85.66666666666667, "TextStructure": 93.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"One of the leaders of Israel is Reuven Rivlin.\". The model generated translation is \"Reuven Rivlin is the leader of Israel.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 98.5, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Cecil Parker had a main role in It's Great to Be Young.\". The model generated translation is \"Cecil Parker stars in It's Great to Be Young.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 89.5, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Hypermarcas, whose main product is drugs, was founded on January 1, 2001 and is located in Brazil.\". The model generated translation is \"Hypermarcas, which produces drugs, is in Brazil. It was founded on January 01, 2001.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.66666666666667, "DataCoverage": 97.0, "Fluency": 95.0, "Relevance": 96.66666666666667, "TextStructure": 95.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Brandon Carter, known for the Carter constant and No-hair theorem, is a professional in the field of general relativity.\". The model generated translation is \"Brandon Carter, known for the Carter constant and the No-hair theorem, worked in General relativity.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.0, "DataCoverage": 94.33333333333333, "Fluency": 94.0, "Relevance": 92.33333333333333, "TextStructure": 93.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Year of No Light is a band whose members include a former guitarist for Monarch has created an album called Nord.\". The model generated translation is \"Year of No Light, who played with Monarch, wrote Nord.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.0, "DataCoverage": 99.0, "Fluency": 99.0, "Relevance": 98.0, "TextStructure": 99.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"George Allen & Unwin published The Fellowship of the Ring, a fantasy, on July 29th, 1954. The Fellowship of the Ring is preceded by the Hobbit and followed by The Two Towers.\". The model generated translation is \"George Allen & Unwin publishes The Fellowship of the Ring, which is Fantasy. The Two Towers follows it. The Fellowship of the Ring was released on July 29, 1954. It follows The Hobbit.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 90.0, "DataCoverage": 94.0, "Fluency": 37.333333333333336, "Relevance": 90.0, "TextStructure": 70.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The album Turn Me On is by the American band The Honeymoon Killers.\". The model generated translation is \"The Honeymoon Killers wrote Turn Me On.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 77.33333333333333, "DataCoverage": 96.66666666666667, "Fluency": 99.33333333333333, "Relevance": 96.33333333333333, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Brandon Carter born in England attended University of Cambridge whose vice chancellor is Leszek Borysiewicz.\". The model generated translation is \"Brandon Carter, who graduated from University of Cambridge, was born in England. Leszek Borysiewicz is the vice-chancellor of University of Cambridge.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.0, "DataCoverage": 96.33333333333333, "Fluency": 70.66666666666667, "Relevance": 91.66666666666667, "TextStructure": 77.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"\"Imagine\" is a song by musical artist, John Lennon.\". The model generated translation is \"John Lennon composed Imagine.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 88.66666666666667, "DataCoverage": 98.66666666666667, "Fluency": 94.0, "Relevance": 94.0, "TextStructure": 98.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Agremiacao Sportiva Arapiraquense club has 17000 members and they play in the Campeonato Brasileiro S\u00e9rie C league based in Brazil. Their ground is the Estadio Municipal Coaracy da Mata Fonseca located in Arapiraca and Vila Nova Futebol Clube are the champions of the league. The chairman of Agremia\u00e7\u00e3o Sportiva Arapiraquense has the title of 'President'.\". The model generated translation is \"Agremia\u00e7\u00e3o Sportiva Arapiraquense play in Campeonato Brasileiro S\u00e9rie C, the champions of which are Vila Nova Futebol Clube. Their stadium has 17,000 seats. Agremia\u00e7\u00e3o Sportiva Arapiraquense play their home games in Est\u00e1dio Municipal Coaracy da Mata Fonseca. The title of their chairman is President. Est\u00e1dio Municipal Coaracy da Mata Fonseca is in Arapiraca. Campeonato Brasileiro S\u00e9rie C is in Brazil.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 83.0, "DataCoverage": 85.66666666666667, "Fluency": 64.0, "Relevance": 83.0, "TextStructure": 60.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The album Turn Me On (which has run time of 35.1 minutes) was preceded by the album Let It Breed; Let It Breed is preceded by the release of the album Love American Style.\". The model generated translation is \"Turn Me On, which follows Let It Breed, has a runtime of 35.1. Let It Breed follows Love American Style.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 89.66666666666667, "DataCoverage": 91.0, "Fluency": 72.33333333333333, "Relevance": 90.0, "TextStructure": 74.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The language code (ISO 639-2) of the English language is eng.\". The model generated translation is \"The iso 6392 code of English language is \"eng\".\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.0, "DataCoverage": 99.0, "Fluency": 92.66666666666667, "Relevance": 98.66666666666667, "TextStructure": 93.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The University of Burgundy has 9400 post-graduate students and employs 2900 staff members.\". The model generated translation is \"University of Burgundy has 2,900 staff members and 9,400 postgraduate students.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.0, "DataCoverage": 99.5, "Fluency": 99.0, "Relevance": 99.0, "TextStructure": 99.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nurhan Atasoy, born January 1st, 1934, was of Turkish nationality.\". The model generated translation is \"Nurhan Atasoy, who is from Turkish people, was born on January 01, 1934.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.33333333333333, "DataCoverage": 95.0, "Fluency": 78.33333333333333, "Relevance": 95.0, "TextStructure": 72.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Abraham Ribicoff was born in the USA. He was married to Casey Ribicoff and was succeeded by John N. Dempsey.\". The model generated translation is \"Casey Ribicoff is the spouse of Abraham A. Ribicoff, which John N. Dempsey succeeded. Abraham A. Ribicoff was born in the United States.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 63.0, "Relevance": 100.0, "TextStructure": 60.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"GMA New Media is a company in the entertainment industry that is located inside the GMA Network Center, which is in the Philippines,.\". The model generated translation is \"GMA New Media is in the entertainment sector in GMA Network Center and Philippines.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 76.0, "DataCoverage": 93.5, "Fluency": 69.0, "Relevance": 94.0, "TextStructure": 87.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Adams County, Pennsylvania, United States is home to the 11th Mississippi Infantry Monument.\". The model generated translation is \"11th Mississippi Infantry Monument is in Adams County, Pennsylvania, the United States.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.0, "DataCoverage": 92.5, "Fluency": 69.5, "Relevance": 88.5, "TextStructure": 76.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Reggae's stylistic origin is rhythm and blues.\". The model generated translation is \"Reggae originates from Rhythm and Blues.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 97.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Aleksandr Prudnikov was born on February 24, 1989 and is 185 cm tall. He currently plays for FC Amkar Perm and also played for FC Terek Grozny, which is located in Grozny.\". The model generated translation is \"Aleksandr Prudnikov currently plays for FC Amkar Perm and measures 185 centimetres. He played for FC Terek Grozny. He was born on February 24, 1989. FC Terek Grozny play their home games in Grozny.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.0, "DataCoverage": 100.0, "Fluency": 86.0, "Relevance": 100.0, "TextStructure": 96.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The band Train followed up \"This'll be my year\" with a 3 minutes, 16 seconds long pop rock song, entitled \"Mermaid.\" Mermaid, which is also considered an example of the reggae genre of music, was written by songwriter, Espen Lind and released on December, 27, 2012.\". The model generated translation is \"Mermaid, released on December 27, 2012, is Pop rock and Reggae. It follows Thisll Be My Year. Espen Lind wrote it. Mermaid has a runtime of 3.16.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.0, "DataCoverage": 72.33333333333333, "Fluency": 89.33333333333333, "Relevance": 99.0, "TextStructure": 93.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Punk blues and noise rock are genre of the album Turn Me On.\". The model generated translation is \"Turn Me On is Punk blues and Noise rock.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 92.0, "DataCoverage": 97.33333333333333, "Fluency": 79.0, "Relevance": 98.0, "TextStructure": 84.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Ciudad Ayala is in Morelos and has a population density of 1604.\". The model generated translation is \"The population density of Ciudad Ayala, which is part of Morelos, is 1,604.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 77.0, "DataCoverage": 100.0, "Fluency": 93.66666666666667, "Relevance": 100.0, "TextStructure": 98.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Bionico is a dessert food found in Mexico where Enrique Pena Nieto is the leader.\". The model generated translation is \"Bionico, which comes from Mexico, is a dessert. Enrique Pe\u00f1a Nieto is the leader of Mexico.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 90.5, "Relevance": 100.0, "TextStructure": 87.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Bootleg Series Volume 1: The Quine Tapes released on October 16, 2001 is 230.05 minutes long.\". The model generated translation is \"Bootleg Series Volume 1: The Quine Tapes, the runtime of which is 230.05, was released on October 16, 2001.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.0, "DataCoverage": 99.0, "Fluency": 65.5, "Relevance": 98.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Though associated with Jwaydan Moyine, trance music was the genre of choice for Andrew Rayel.\". The model generated translation is \"Andrew Rayel plays Trance music and played with Jwaydan Moyine.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.0, "DataCoverage": 99.0, "Fluency": 95.0, "Relevance": 96.66666666666667, "TextStructure": 96.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Piotr Hallmann is 175.26 cm tall and weighs 70.308 kg.\". The model generated translation is \"Piotr Hallmann, whose weight is 70.308, measures 175.26 centimetres.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 93.33333333333333, "DataCoverage": 85.33333333333333, "Fluency": 77.0, "Relevance": 91.33333333333333, "TextStructure": 95.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Mason School of Business are the current tenants of Alan B Miller Hall, which was completed on June 1, 2009.\". The model generated translation is \"Alan B. Miller Hall, completed on June 01, 2009, houses the Mason School of Business.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 78.66666666666667, "DataCoverage": 81.33333333333333, "Fluency": 69.33333333333333, "Relevance": 82.66666666666667, "TextStructure": 68.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nurhan Atasoy is a resident of Istanbul, Turkey. Istanbul is in the Eastern European Summer Time zone.\". The model generated translation is \"Nurhan Atasoy lives in Istanbul and Turkey. Istanbul is in the Eastern European Time time zone.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 76.0, "DataCoverage": 76.33333333333333, "Fluency": 68.33333333333333, "Relevance": 85.0, "TextStructure": 66.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The University of Burgundy is located in the city of Dijon, has 27400 students, 16800 undergraduate students, 2900 staff members and 1299 doctoral students.\". The model generated translation is \"The University of Burgundy, which is in Dijon, has 16,800 undergraduate students, 2,900 staff members, 27,400 students and 1,299 doctoral students.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 98.33333333333333, "Relevance": 100.0, "TextStructure": 98.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The total area of water in New Jersey is 3,544 square kilometers.\". The model generated translation is \"New Jersey has a water area of 3544040000.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 72.0, "DataCoverage": 85.0, "Fluency": 82.5, "Relevance": 90.5, "TextStructure": 82.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The College of William and Mary is the owner of the Alan B. Miller Hall which was completed on 1st June 2009, address is \"101 Ukrop Way\". The Mason School of Business are the current tenants of Alan B Miller Hall.\". The model generated translation is \"Alan B. Miller Hall, which houses the Mason School of Business, is located at 101 Ukrop Way. It was completed on June 01, 2009. College of William & Mary owns it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.66666666666667, "DataCoverage": 99.33333333333333, "Fluency": 88.66666666666667, "Relevance": 98.66666666666667, "TextStructure": 90.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The 11th Mississippi Infantry monument (located in Adams county, Pennsylvania) was established in the year 2000. Adams county, Pennsylvania has Cumberland county, Pennsylvania to its north.\". The model generated translation is \"11th Mississippi Infantry Monument, which is in Adams County, Pennsylvania, was established in 2000. Cumberland County, Pennsylvania is located to the north of Adams County, Pennsylvania.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.0, "DataCoverage": 99.0, "Fluency": 76.0, "Relevance": 97.0, "TextStructure": 68.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The population in the Ciudad Ayala metropolitan area is 1777539.\". The model generated translation is \"The metropolitan area of Ciudad Ayala has a population of 1,777,539.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.33333333333333, "DataCoverage": 100.0, "Fluency": 87.66666666666667, "Relevance": 96.66666666666667, "TextStructure": 91.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"To the northeast of Frederick County, Maryland is Adams County, Pennsylvania, the location of the 11th Mississippi Infantry Monument. The monument is a Contributing Property.\". The model generated translation is \"11th Mississippi Infantry Monument is in Adams County, Pennsylvania (contributing property). Frederick County, Maryland is located to the southwest there.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.66666666666667, "DataCoverage": 98.33333333333333, "Fluency": 87.33333333333333, "Relevance": 98.66666666666667, "TextStructure": 94.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The currency of Mexico is the peso and the local people are called Mexicans. In Mexico there is a region called Jalisco which makes a dessert called bionico that requires granola as one of its ingredients.\". The model generated translation is \"Bionico, found in Jalisco, contains granola. It comes from Mexico. The currency of Mexico is the Mexican peso. Mexicans live in Mexico.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 95.66666666666667, "DataCoverage": 95.0, "Fluency": 96.0, "Relevance": 93.66666666666667, "TextStructure": 95.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Ciudad Ayala (a city in Mexico) has a leader called the Governator and it is part of Morelos.\". The model generated translation is \"The Governator governs Ciudad Ayala, which is part of Morelos. Ciudad Ayala is in Mexico.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 64.0, "DataCoverage": 73.0, "Fluency": 26.0, "Relevance": 73.0, "TextStructure": 48.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Brandon Carter was born in 1942 on January, 1 and graduated from the University of Cambridge. He is best known for creating the Penrose diagram.\". The model generated translation is \"Brandon Carter, born on January 01, 1942, is known for the Penrose diagram. He graduated from University of Cambridge.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Pontiac Rageous was a car that went into production in 1997 and was manufactured by Pontiac. Pontiac was founded in the United States, and one of the successors of Pontiac is Buick.\". The model generated translation is \"Pontiac, founded in the United States, manufactured the Pontiac Rageous. The production of the Pontiac Rageous started in 1997. Buick succeeded Pontiac.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 95.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Ciudad Ayala UTC offset is -6 in the country of Mexico.\". The model generated translation is \"Ciudad Ayala, which is in Mexico, has a UTC offset of \u22126.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The 11th Mississippi Infantry Monument is in the United States in a place called the municipality of Gettysburg in Adams County, Pennsylvania. This place has to its southeast Carroll County, Maryland and to its north Pennsylvania's Cumberland County. The 11th Mississippi Infantry Monument is classified as a contributing property.\". The model generated translation is \"11th Mississippi Infantry Monument is in Adams County, Pennsylvania (contributing property), Gettysburg, Pennsylvania, the United States. Carroll County, Maryland is located to the southeast of Adams County, Pennsylvania. Cumberland County, Pennsylvania is located to the north of Adams County, Pennsylvania.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 79.33333333333333, "DataCoverage": 80.66666666666667, "Fluency": 64.33333333333333, "Relevance": 70.0, "TextStructure": 63.666666666666664}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Live at Roadburn 2008 by Year of No Light was produced by the Roadburn Festival.\". The model generated translation is \"Roadburn Festival produced Live at Roadburn 2008.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.0, "DataCoverage": 99.0, "Fluency": 74.0, "Relevance": 99.0, "TextStructure": 76.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The OS grid reference for Darlington is NZ289147.\". The model generated translation is \"The grid reference of Darlington is NZ289147.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Aaron Turner was born in Massachusetts and is a post metal musician who plays electric guitar and played with the band Twilight.\". The model generated translation is \"Aaron Turner plays Post-metal and electric guitar and played with Twilight. He is from Massachusetts.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.33333333333333, "DataCoverage": 100.0, "Fluency": 64.66666666666667, "Relevance": 100.0, "TextStructure": 73.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Expect a Miracle is in the instrumental music genre.\". The model generated translation is \"Expect a Miracle is Instrumental music.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 88.0, "DataCoverage": 52.0, "Fluency": 76.33333333333333, "Relevance": 89.66666666666667, "TextStructure": 80.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Abdul Taib Mahmud, member of the Parti Pesaka Bumiputera Bersatu party, resides in Demak Jaya, Jalan Bako, Kuching, Sarawak.\". The model generated translation is \"Abdul Taib Mahmud, which belongs to the Parti Pesaka Bumiputera Bersatu, lives in Demak Jaya, Jalan Bako, Kuching, Sarawak.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 93.0, "DataCoverage": 100.0, "Fluency": 86.0, "Relevance": 100.0, "TextStructure": 97.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The University of Burgundy has 16,800 undergraduate students.\". The model generated translation is \"The University of Burgundy has 16,800 undergraduate students.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The place served by the Bedford Aerodrome located in Thurleigh is the Bedford Autodrome.\". The model generated translation is \"The Bedford Aerodrome, which is in Thurleigh, serves Bedford Autodrome.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 94.5, "Relevance": 100.0, "TextStructure": 95.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Expect a Miracle has a runtime of 54:56.\". The model generated translation is \"Expect a Miracle has a runtime of 54.56.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 98.0, "Relevance": 100.0, "TextStructure": 98.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nie Haisheng, born in Zaoyang took part in the Shenzhou 6 mission was part of the mission Shenzhou 10.\". The model generated translation is \"Nie Haisheng, born in Zaoyang, was a crew member of Shenzhou 10 and Shenzhou 6.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 97.66666666666667, "Fluency": 95.0, "Relevance": 99.66666666666667, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The 89-minute-long movie English Without Tears includes music composed by Nicholas Brodszky. Alan Jaggs was in charge of the editing.\". The model generated translation is \"Nicholas Brodszky composed the music of English Without Tears. The editor of English Without Tears, the runtime of which is 89, is Alan Jaggs.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 85.0, "DataCoverage": 97.0, "Fluency": 81.0, "Relevance": 95.0, "TextStructure": 84.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"English Without Tears is 89 minutes long.\". The model generated translation is \"English Without Tears has a runtime of 89.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.0, "DataCoverage": 99.66666666666667, "Fluency": 99.0, "Relevance": 99.0, "TextStructure": 99.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nie Haisheng is from the People's Republic of China, he was born in Zaoyang, Hubei.\". The model generated translation is \"Nie Haisheng, who is from the People's Republic of China, was born in Hubei, Zaoyang.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.0, "DataCoverage": 84.33333333333333, "Fluency": 94.33333333333333, "Relevance": 97.66666666666667, "TextStructure": 94.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Andrew Rayel who performed the genre of Trance music is associated with the musical artist Armin van Buuren.\". The model generated translation is \"Andrew Rayel plays Trance music and played with Armin van Buuren.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 89.0, "DataCoverage": 63.0, "Fluency": 86.33333333333333, "Relevance": 79.0, "TextStructure": 89.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The music of the film English Without Tears is composed by Nicholas Brodszky with Harold French as the director.\". The model generated translation is \"Nicholas Brodszky composed the music of English Without Tears. Harold French is the director of English Without Tears.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.5, "DataCoverage": 99.0, "Fluency": 57.0, "Relevance": 98.5, "TextStructure": 99.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The periapsis of 1147 Stavropolis is 260855000000.\". The model generated translation is \"The periapsis of 1147 Stavropolis is 260,855,000,000.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Agremia\u00e7\u00e3o Sportiva Arapiraquense's full name is \"Agremia\u00e7\u00e3o Sportiva Arapiraquense\" and they played in the Campeonato Brasileiro S\u00e9rie C league in the 2015 season from Brazil and Vila Nova Futebol Clube have been champions. The Est\u00e1dio Municipal Coaracy da Mata Fonseca is the name of the ground of Agremia\u00e7\u00e3o Sportiva Arapiraquense located in Arapiraca.\". The model generated translation is \"The champions of the Campeonato Brasileiro S\u00e9rie C, which is in Brazil, are Vila Nova Futebol Clube. Agremia\u00e7\u00e3o Sportiva Arapiraquense play in Campeonato Brasileiro S\u00e9rie C and are their full name. They played in the 2015 season. They play their home games in Est\u00e1dio Municipal Coaracy da Mata Fonseca. Est\u00e1dio Municipal Coaracy da Mata Fonseca is in Arapiraca.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 84.0, "DataCoverage": 93.33333333333333, "Fluency": 66.0, "Relevance": 88.0, "TextStructure": 81.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Acharya Institute of Technology which is in India, is affiliated with Visvesvaraya Technological University and was given the Technical Campus status by The All India Council for Technical Education which is in Mumbai. The campus address for the Acharya Institute of Technology is: Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore - 560090.\". The model generated translation is \"Acharya Institute of Technology, which is affiliated with Visvesvaraya Technological University, is located at In Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore \u2013 560090. Acharya Institute of Technology, to which All India Council for Technical Education gave the status of 'Technical Campus', is in India. All India Council for Technical Education is in Mumbai.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 93.33333333333333, "DataCoverage": 94.66666666666667, "Fluency": 83.33333333333333, "Relevance": 90.33333333333333, "TextStructure": 86.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"MotorSport Vision is located in the city of Fawkham.\". The model generated translation is \"The MotorSport Vision serves Fawkham.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 61.666666666666664, "DataCoverage": 35.333333333333336, "Fluency": 81.0, "Relevance": 40.333333333333336, "TextStructure": 82.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"After releasing their album Squeeze, music group the Velvet Underground produced and released rock music album Bootleg Series Volume 1: The Quine Tapes, which they recorded in St Louis Missouri, USA The album was released on 2001-10-16 under the Polydor and Universal Music Group record labels and has a total run time of 230:05 minutes.\". The model generated translation is \"Bootleg Series Volume 1: The Quine Tapes, which follows Squeeze, was recorded in the United States and St. Louis, Missouri. Its labels are Polydor Records and Universal Music Group. Bootleg Series Volume 1: The Quine Tapes was released on October 16, 2001. It has a runtime of 230.05.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 89.33333333333333, "DataCoverage": 86.66666666666667, "Fluency": 75.33333333333333, "Relevance": 87.66666666666667, "TextStructure": 76.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The ALCO RS-3 was produced between May 1950 and August 1956 has has a cylinder count of 12 and is 17068.8 millimetres in length.\". The model generated translation is \"ALCO RS-3, which has 12 cylinders, was made in May 1950 - August 1956. Its length is 17,068.8 millimetres.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.33333333333333, "DataCoverage": 96.33333333333333, "Fluency": 89.66666666666667, "Relevance": 97.0, "TextStructure": 89.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Pontiac Rageous was a car with a coupe body style that was manufactured by Pontiac, first produced in 1997 and last produced in 1997 as well.\". The model generated translation is \"The production of the Pontiac Rageous started in 1997. Pontiac Rageous, which is a coupe, was last made in 1997. Pontiac manufactured it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.33333333333333, "DataCoverage": 95.66666666666667, "Fluency": 90.0, "Relevance": 97.0, "TextStructure": 92.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Est\u00e1dio Municipal Coaracy da Mata Fonseca is a stadium in Arapiraca. It is the home ground of Agremia\u00e7\u00e3o Sportiva Arapiraquense of the Brazilian Championship Series C where the champions are Vila Nova Futebol Clube. The Brazilian name for the championship is Campeonato Brasileiro S\u00e9rie C, and Agremia\u00e7\u00e3o Sportiva Arapiraquense competed there in 2015. The club has 17,000 members.\". The model generated translation is \"Est\u00e1dio Municipal Coaracy da Mata Fonseca, in which Agremia\u00e7\u00e3o Sportiva Arapiraquense play their home games, is in Arapiraca. Agremia\u00e7\u00e3o Sportiva Arapiraquense play in Campeonato Brasileiro S\u00e9rie C, the champions of which are Vila Nova Futebol Clube. They played in the 2015 season. Their stadium has 17,000 seats. The full name of Agremia\u00e7\u00e3o Sportiva Arapiraquense is Agremia\u00e7\u00e3o Sportiva Arapiraquense.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 76.66666666666667, "DataCoverage": 96.33333333333333, "Fluency": 78.33333333333333, "Relevance": 95.0, "TextStructure": 75.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The song Mermaid is by the musical band Train.\". The model generated translation is \"Train composed Mermaid.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 54.0, "DataCoverage": 62.0, "Fluency": 85.33333333333333, "Relevance": 60.666666666666664, "TextStructure": 84.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Agremiacao Sportiva Arapiraquense play in the Campeonato Brasileiro Serie C league based in Brazil in 2015. Their ground is the Estadio Municipal Coaracy da Mata Fonseca located in Arapiraca.\". The model generated translation is \"Agremia\u00e7\u00e3o Sportiva Arapiraquense play in Campeonato Brasileiro S\u00e9rie C, which is in Brazil. They played in the 2015 season. They play their home games in Est\u00e1dio Municipal Coaracy da Mata Fonseca. Est\u00e1dio Municipal Coaracy da Mata Fonseca is in Arapiraca.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.0, "DataCoverage": 94.66666666666667, "Fluency": 88.66666666666667, "Relevance": 92.66666666666667, "TextStructure": 91.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"\"English Without Tears\" was produced and written by Anatole de Grunwald. The editor for the film was Alan Jaggs.\". The model generated translation is \"The editor of English Without Tears, which Anatole de Grunwald produced, is Alan Jaggs. Anatole de Grunwald wrote English Without Tears.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 74.5, "Relevance": 100.0, "TextStructure": 73.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Train followed Mermaid with Imagine is a song by musical artist John Lennon, which has a FIMI certification. It was produced by the production team Espionage.\". The model generated translation is \"Imagine, which was certified by FIMI, follows Mermaid, which Espionage produced. John Lennon composed it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 80.66666666666667, "DataCoverage": 85.33333333333333, "Fluency": 77.66666666666667, "Relevance": 74.66666666666667, "TextStructure": 80.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Pontiac Rageous went into production in 1997 and ended the same year.\". The model generated translation is \"The production of the Pontiac Rageous started in 1997. Pontiac Rageous was last made in 1997.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 81.0, "DataCoverage": 86.33333333333333, "Fluency": 57.0, "Relevance": 84.33333333333333, "TextStructure": 67.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Bionico is a dessert found in Mexico where peso is the currency. Cookie is also a dessert.\". The model generated translation is \"Bionico, which comes from Mexico, is a dessert. Cookie can be a variation of Dessert. The currency of Mexico is the Mexican peso.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.66666666666667, "DataCoverage": 98.66666666666667, "Fluency": 86.66666666666667, "Relevance": 99.33333333333333, "TextStructure": 93.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Brian Kelly produced an instrumental album titled Expect A Miracle.\". The model generated translation is \"Brian Kelly produced Expect a Miracle, which is Instrumental music.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.0, "DataCoverage": 88.0, "Fluency": 87.0, "Relevance": 98.66666666666667, "TextStructure": 85.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Detroit is part of Michigan.\". The model generated translation is \"Detroit is part of Michigan.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.66666666666667, "DataCoverage": 96.66666666666667, "Fluency": 98.66666666666667, "Relevance": 98.66666666666667, "TextStructure": 97.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Nicholas Brodszky has a non-performing background.\". The model generated translation is \"Nicholas Brodszky was a non performing personnel.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 53.5, "DataCoverage": 94.0, "Fluency": 66.0, "Relevance": 100.0, "TextStructure": 75.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Bootleg Series Volume 1: The Quine Tapes by Velvet Underground, a rock music genre, was released on October, 16, 2001 by Universal Music Group and Polydor Records.The Quine Tapes was preceded by Squeeze by The Velvet Underground.\". The model generated translation is \"The Velvet Underground wrote Bootleg Series Volume 1: The Quine Tapes, which is Rock music. Bootleg Series Volume 1: The Quine Tapes, the labels of which are Polydor Records and Universal Music Group, follows Squeeze. It was released on October 16, 2001.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.0, "DataCoverage": 98.66666666666667, "Fluency": 97.66666666666667, "Relevance": 87.33333333333333, "TextStructure": 98.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Bootleg Series Volume I: The Quine Tapes was recorded in the United States.\". The model generated translation is \"Bootleg Series Volume 1: The Quine Tapes was recorded in the United States.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 95.33333333333333, "DataCoverage": 92.0, "Fluency": 90.66666666666667, "Relevance": 90.33333333333333, "TextStructure": 92.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The College of William and Mary, located in Williamsburg Virginia is the location of the Mason School of Business located inside Alan B Miller Hall.\". The model generated translation is \"Alan B. Miller Hall, which is in Williamsburg, Virginia, houses the Mason School of Business. College of William & Mary owns it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.5, "DataCoverage": 98.0, "Fluency": 76.5, "Relevance": 99.0, "TextStructure": 87.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Train followed Mermaid with Imagine, a song by John Lennon was produced by the production team Espionage and written by Pat Monahan.\". The model generated translation is \"Imagine follows Mermaid, which Espionage produced. Pat Monahan wrote it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 74.66666666666667, "DataCoverage": 94.66666666666667, "Fluency": 65.66666666666667, "Relevance": 93.0, "TextStructure": 86.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Brandon Carter, a specialist in General Relativity, is known for the Carter Constant.\". The model generated translation is \"Brandon Carter, known for the Carter constant, worked in General relativity.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 97.33333333333333, "DataCoverage": 98.66666666666667, "Fluency": 93.0, "Relevance": 99.66666666666667, "TextStructure": 96.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Darinka Dentcheva is resident of new Jersey which has an area of water that is 3.544.04 meters squared and citizen of the United States where the motto is \"In God We Trust\".\". The model generated translation is \"Darinka Dentcheva, which is from the United States, lives in New Jersey and the United States. New Jersey has a water area of 3544040000. The motto of the United States is In God we trust.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 92.0, "DataCoverage": 100.0, "Fluency": 64.66666666666667, "Relevance": 87.33333333333333, "TextStructure": 66.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Lancashire native Bill Oddie starred in Bananaman, a story created by Steve Bright filmed in London at Broadcasting House, the home of the BBC who also broadcast it.\". The model generated translation is \"Bill Oddie, born in Lancashire, stars in Bananaman, which Steve Bright created. BBC, which is in Broadcasting House, broadcasts it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 96.66666666666667, "Fluency": 91.0, "Relevance": 98.66666666666667, "TextStructure": 96.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Acharya Institute of Technology is in Bangalore, Karnataka.\". The model generated translation is \"The Acharya Institute of Technology is in Bangalore, Karnataka.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 100.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Lady Anne Monson was born in the Kingdom of England whose capital was previously Winchester.\". The model generated translation is \"Lady Anne Monson was born in the Kingdom of England. The capital of the Kingdom of England is Winchester.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 95.0, "DataCoverage": 93.66666666666667, "Fluency": 78.0, "Relevance": 94.66666666666667, "TextStructure": 96.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Death on a Factory Farm, produced and directed by Tom Simon and edited by Geof Bartz was broadcast by HBO. The music was composed by Jamie Lawrence and Sarah Teale was co-producer.\". The model generated translation is \"Tom Simon is the director of Death on a Factory Farm, which Tom Simon and Sarah Teale produced. HBO broadcasts Death on a Factory Farm. The editor of Death on a Factory Farm is Geof Bartz. Jamie Lawrence composed the music of Death on a Factory Farm.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 79.33333333333333, "Relevance": 100.0, "TextStructure": 89.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The All India Council for Technical Education located in Mumbai was proud to give the Technical Campus status to the Acharya Institute of Technology. The Acharya Institute of Technology is affiliated with Visvesvaraya Technological University which is located at Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore - 560090.\". The model generated translation is \"Acharya Institute of Technology, which is affiliated with Visvesvaraya Technological University, is located at In Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore \u2013 560090. The Acharya Institute of Technology, to which All India Council for Technical Education gave the status of 'Technical Campus', is in Bangalore. All India Council for Technical Education is in Mumbai.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.0, "DataCoverage": 99.66666666666667, "Fluency": 90.66666666666667, "Relevance": 99.66666666666667, "TextStructure": 98.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Aaron Turner is a singer who was born in Boston. His music is post-metal, and he played with the band twilight.\". The model generated translation is \"Aaron Turner plays Post-metal and singing and played with Twilight. He is from Boston.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.33333333333333, "DataCoverage": 98.0, "Fluency": 82.66666666666667, "Relevance": 97.0, "TextStructure": 93.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The location of Bedford Aerodrome is Thurleigh and it has a runway whose length is 1095.\". The model generated translation is \"The length of the runway of Bedford Aerodrome is 1,095. Bedford Aerodrome is in Thurleigh.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 94.5, "Relevance": 100.0, "TextStructure": 95.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Adam West was born in the year 1928.\". The model generated translation is \"Adam West was born in 1928.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.66666666666667, "DataCoverage": 98.33333333333333, "Fluency": 98.66666666666667, "Relevance": 99.33333333333333, "TextStructure": 99.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Fellowship of the Ring belongs to the fantasy genre.\". The model generated translation is \"The Fellowship of the Ring is Fantasy.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 66.5, "DataCoverage": 63.5, "Fluency": 60.0, "Relevance": 98.0, "TextStructure": 80.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The song Mermaid by Train (written by Espen Lind) was release on December 27, 2012. Mermaid has a total runtime of 3 minutes and 16 seconds, and belongs to the pop rock genre. Mermaid is preceded by the song This'll be my year.\". The model generated translation is \"Mermaid, the runtime of which is 3.16, is Pop rock. It was released on December 27, 2012. Mermaid, which was written by Espen Lind, follows Thisll Be My Year.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 85.0, "DataCoverage": 98.5, "Fluency": 62.0, "Relevance": 97.5, "TextStructure": 69.5}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Pontiac Rageous was a car with a coupe body style manufactured by Pontiac. Assembled in both Michigan and Detroit, it went into production in 1997, ending in the same year.\". The model generated translation is \"The production of the Pontiac Rageous started in 1997. Pontiac Rageous, last made in 1997, was assembled in Michigan and Detroit. The Pontiac Rageous, which Pontiac manufactured, is a coupe.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 77.33333333333333, "Relevance": 100.0, "TextStructure": 81.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The All India Council for Technical Education was proud to give the Technical Campus status to the Acharya Institute of Technology located in Bangalore. The Institute is affiliated with Visvesvaraya Technological University.\". The model generated translation is \"Acharya Institute of Technology, which is in Bangalore, is affiliated with Visvesvaraya Technological University. All India Council for Technical Education gave the status of 'Technical Campus' to it.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 96.0, "DataCoverage": 100.0, "Fluency": 94.0, "Relevance": 100.0, "TextStructure": 100.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Aaron Turner starter performing in 1995 and began singing for a living. He performs under the genre of post-metal, and is noted to have played with the band Twilight.\". The model generated translation is \"Aaron Turner plays Post-metal and singing and played with Twilight. He was active from 1995.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 87.0, "DataCoverage": 86.33333333333333, "Fluency": 77.33333333333333, "Relevance": 79.0, "TextStructure": 84.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Lady Anne Monson lived in the Kingdom of England and held British nationality but resided in India for most of her life. Pranab Mukherjee is the leader of India, which has a total area of 32875900000000.\". The model generated translation is \"Lady Anne Monson, which is from the Kingdom of England, lives in India. Pranab Mukherjee is the leader of India, the total area of which is 3,287,590,000,000.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 99.0, "DataCoverage": 99.66666666666667, "Fluency": 83.66666666666667, "Relevance": 96.0, "TextStructure": 94.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Chinabank was founded on August 16,1920 and the bank has 295 centers and provides services to customers. Chinabank's net income is 15,100,000,000.\". The model generated translation is \"Chinabank, which has 295 branches and a net income of $15,100,000,000, offers Banking services. It was founded on August 16, 1920.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 93.33333333333333, "DataCoverage": 93.33333333333333, "Fluency": 93.0, "Relevance": 96.33333333333333, "TextStructure": 91.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Musical group the Velvet Underground released The album The Bootleg Series Volume 1: The Quine Tapes, which was recorded under the Universal Music Group and its parent company Vivendi. A former member of the band was Lou Reed.\". The model generated translation is \"The label of Bootleg Series Volume 1: The Quine Tapes, which The Velvet Underground wrote, is Universal Music Group, the parent company of which is Vivendi. Lou Reed is a former member of The Velvet Underground.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.33333333333333, "DataCoverage": 92.0, "Fluency": 95.66666666666667, "Relevance": 96.66666666666667, "TextStructure": 98.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"La Crosse is a city in La Crosse County in the U.S. state of Wisconsin.\". The model generated translation is \"La Crosse, Wisconsin is part of La Crosse County, Wisconsin.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 98.33333333333333, "DataCoverage": 97.33333333333333, "Fluency": 93.33333333333333, "Relevance": 98.66666666666667, "TextStructure": 99.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Agremia\u00e7\u00e3o Sportiva Arapiraquense with 17000 members play in the Brazil Campeonato Brasileiro S\u00e9rie C league. Est\u00e1dio Municipal Coaracy da Mata Fonseca in located in Arapiraca and ground is Agremia\u00e7\u00e3o Sportiva Arapiraquense.\". The model generated translation is \"Agremia\u00e7\u00e3o Sportiva Arapiraquense play in Campeonato Brasileiro S\u00e9rie C, which is in Brazil. Their stadium has 17,000 seats. Agremia\u00e7\u00e3o Sportiva Arapiraquense play their home games in Est\u00e1dio Municipal Coaracy da Mata Fonseca. Est\u00e1dio Municipal Coaracy da Mata Fonseca is in Arapiraca.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 95.33333333333333, "DataCoverage": 98.0, "Fluency": 98.0, "Relevance": 96.66666666666667, "TextStructure": 89.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"The Fellowship of the Ring was written by J.R.R Tolkien. The Two Towers is the sequel to it. It was preceded by the Hobbit. The Hobbit's genre is juvenile fantasy and literary genre is high fantasy.\". The model generated translation is \"The Two Towers follows The Fellowship of the Ring, which J. R. R. Tolkien wrote. The Fellowship of the Ring follows The Hobbit, which is Juvenile fantasy and High fantasy.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 94.66666666666667, "DataCoverage": 66.66666666666667, "Fluency": 93.33333333333333, "Relevance": 95.0, "TextStructure": 90.33333333333333}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Ciudad Ayala city, led by Juan Nolasco, has a population density of 1604.0.\". The model generated translation is \"The population density of Ciudad Ayala, the leader of which is Juan Nolasco, is 1,604.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 100.0, "DataCoverage": 100.0, "Fluency": 75.0, "Relevance": 100.0, "TextStructure": 75.0}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Year of No Light is both the artist and the producer of the album Nord. The album was released on the label Crucial Blast. Year of No Light's next album was Live at Roadburn 2008.\". The model generated translation is \"Live at Roadburn 2008 follows Nord, which Year of No Light produced. Year of No Light wrote it. The label of Nord is Crucial Blast.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 71.66666666666667, "DataCoverage": 81.66666666666667, "Fluency": 49.333333333333336, "Relevance": 84.33333333333333, "TextStructure": 69.66666666666667}}, {"input": "You are evaluating Chinese-to-English Machine translation task. The correct translation is \"Mermaid,performed by Train, is on the Sony Music Entertainment label;however,John Lennon also released Imagine which was followed by Happy Xmas (War is Over) on the same record label.\". The model generated translation is \"The label of Mermaid, which Imagine follows, is Sony Music Entertainment. Happy Xmas follows Imagine.\n\". Please identify all errors within each model output, up to a maximum of five. For each error, please give me the corresponding error type, major/minor label, error location of the model generated translation and explanation for the error. Major errors can confuse or mislead the reader due to significant change in meaning, while minor errors don't lead to loss of meaning but will be noticed.", "output": {"Correctness": 88.0, "DataCoverage": 85.0, "Fluency": 38.5, "Relevance": 100.0, "TextStructure": 50.5}}]}